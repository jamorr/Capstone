{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from preprocessing.pipeline import (\n",
    "    combine_data_NYPD,\n",
    "    get_preprocessed_data,\n",
    "    preprocess_311,\n",
    "    process_crime_data,\n",
    "    query_data,\n",
    ")\n",
    "from preprocessing.weather_parse import weather_parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 311 data...\n"
     ]
    }
   ],
   "source": [
    "year = 2017\n",
    "preprocessed_dir = pathlib.Path(f\"../data/combined/year={year}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(\n",
    "        preprocessed_dir,\n",
    "        )\n",
    "    assert len(df) != 0\n",
    "except AssertionError:\n",
    "    df = get_preprocessed_data(\n",
    "        start_date=year,\n",
    "        end_date=year+1,\n",
    "        sectors=False,\n",
    "        opened_created_add=['borough', 'precinct', 'complaint_type'],\n",
    "    ).convert_dtypes(dtype_backend='pyarrow')\n",
    "    df.to_parquet(preprocessed_dir, partition_cols=['borough', 'precinct'])\n",
    "except FileNotFoundError:\n",
    "    preprocessed_dir.mkdir()\n",
    "    df = get_preprocessed_data(\n",
    "        start_date=year,\n",
    "        end_date=year+1,\n",
    "        sectors=False,\n",
    "        opened_created_add=['borough', 'precinct', 'complaint_type'],\n",
    "    ).convert_dtypes(dtype_backend='pyarrow')\n",
    "\n",
    "    df.to_parquet(preprocessed_dir, partition_cols=['borough', 'precinct'])\n",
    "except ValueError:\n",
    "    boroughs = []\n",
    "    for file_path in preprocessed_dir.glob('*'):\n",
    "\n",
    "        if file_path.is_dir():\n",
    "            try:\n",
    "                boroughs.append(pd.read_parquet(file_path))\n",
    "                # print(df)\n",
    "            except Exception:\n",
    "                print(file_path)\n",
    "\n",
    "    df = pd.concat(boroughs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>precinct</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>created_H</th>\n",
       "      <th>closed_H</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>precip_period_hrs</th>\n",
       "      <th>precip_accumulation_mm</th>\n",
       "      <th>direction_deg</th>\n",
       "      <th>speed_mps</th>\n",
       "      <th>dew_temperature_c</th>\n",
       "      <th>year</th>\n",
       "      <th>date_H</th>\n",
       "      <th>FELONY</th>\n",
       "      <th>MISDEMEANOR</th>\n",
       "      <th>VIOLATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>2018-01-01 00:53:55</td>\n",
       "      <td>2018-01-01 12:36:09</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>320</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>2018-01-01 00:23:08</td>\n",
       "      <td>2018-01-01 13:20:33</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>320</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>2018-01-01 00:11:41</td>\n",
       "      <td>2018-01-01 03:49:38</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>320</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Blocked Driveway</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>2018-01-01 00:58:30</td>\n",
       "      <td>2018-01-01 01:52:26</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Partial Access</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>320</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>2018-01-01 00:37:19</td>\n",
       "      <td>2018-01-01 10:39:12</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>320</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576302</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:11:03</td>\n",
       "      <td>2019-12-31 23:47:57</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576303</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:09:15</td>\n",
       "      <td>2019-12-31 23:14:38</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576304</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:01:19</td>\n",
       "      <td>2019-12-31 23:20:27</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Blocked Hydrant</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576305</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:18:27</td>\n",
       "      <td>2019-12-31 23:20:06</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576306</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>123.0</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>2019-12-31 23:00:02</td>\n",
       "      <td>2019-12-31 23:31:21</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1576307 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               borough precinct       complaint_type            created_H  \\\n",
       "0                BRONX     40.0  Noise - Residential  2018-01-01 00:00:00   \n",
       "1                BRONX     40.0  Noise - Residential  2018-01-01 00:00:00   \n",
       "2                BRONX     42.0  Noise - Residential  2018-01-01 00:00:00   \n",
       "3                BRONX     43.0     Blocked Driveway  2018-01-01 00:00:00   \n",
       "4                BRONX     44.0  Noise - Residential  2018-01-01 00:00:00   \n",
       "...                ...      ...                  ...                  ...   \n",
       "1576302         QUEENS    104.0  Noise - Residential  2019-12-31 23:00:00   \n",
       "1576303         QUEENS    108.0  Noise - Residential  2019-12-31 23:00:00   \n",
       "1576304         QUEENS    112.0      Illegal Parking  2019-12-31 23:00:00   \n",
       "1576305         QUEENS    112.0  Noise - Residential  2019-12-31 23:00:00   \n",
       "1576306  STATEN ISLAND    123.0  Noise - Residential  2019-12-31 23:00:00   \n",
       "\n",
       "                    closed_H         created_date          closed_date agency  \\\n",
       "0        2018-01-01 12:00:00  2018-01-01 00:53:55  2018-01-01 12:36:09   NYPD   \n",
       "1        2018-01-01 13:00:00  2018-01-01 00:23:08  2018-01-01 13:20:33   NYPD   \n",
       "2        2018-01-01 03:00:00  2018-01-01 00:11:41  2018-01-01 03:49:38   NYPD   \n",
       "3        2018-01-01 01:00:00  2018-01-01 00:58:30  2018-01-01 01:52:26   NYPD   \n",
       "4        2018-01-01 10:00:00  2018-01-01 00:37:19  2018-01-01 10:39:12   NYPD   \n",
       "...                      ...                  ...                  ...    ...   \n",
       "1576302  2019-12-31 23:00:00  2019-12-31 23:11:03  2019-12-31 23:47:57   NYPD   \n",
       "1576303  2019-12-31 23:00:00  2019-12-31 23:09:15  2019-12-31 23:14:38   NYPD   \n",
       "1576304  2019-12-31 23:00:00  2019-12-31 23:01:19  2019-12-31 23:20:27   NYPD   \n",
       "1576305  2019-12-31 23:00:00  2019-12-31 23:18:27  2019-12-31 23:20:06   NYPD   \n",
       "1576306  2019-12-31 23:00:00  2019-12-31 23:00:02  2019-12-31 23:31:21   NYPD   \n",
       "\n",
       "               descriptor  status  ... precip_period_hrs  \\\n",
       "0        Loud Music/Party  Closed  ...              <NA>   \n",
       "1        Loud Music/Party  Closed  ...              <NA>   \n",
       "2        Loud Music/Party  Closed  ...              <NA>   \n",
       "3          Partial Access  Closed  ...              <NA>   \n",
       "4        Loud Music/Party  Closed  ...              <NA>   \n",
       "...                   ...     ...  ...               ...   \n",
       "1576302  Loud Music/Party  Closed  ...              <NA>   \n",
       "1576303  Loud Music/Party  Closed  ...              <NA>   \n",
       "1576304   Blocked Hydrant  Closed  ...              <NA>   \n",
       "1576305  Loud Music/Party  Closed  ...              <NA>   \n",
       "1576306  Loud Music/Party  Closed  ...              <NA>   \n",
       "\n",
       "        precip_accumulation_mm  direction_deg  speed_mps dew_temperature_c  \\\n",
       "0                         <NA>            320        8.2             -18.3   \n",
       "1                         <NA>            320        8.2             -18.3   \n",
       "2                         <NA>            320        8.2             -18.3   \n",
       "3                         <NA>            320        8.2             -18.3   \n",
       "4                         <NA>            320        8.2             -18.3   \n",
       "...                        ...            ...        ...               ...   \n",
       "1576302                   <NA>           <NA>       <NA>              <NA>   \n",
       "1576303                   <NA>           <NA>       <NA>              <NA>   \n",
       "1576304                   <NA>           <NA>       <NA>              <NA>   \n",
       "1576305                   <NA>           <NA>       <NA>              <NA>   \n",
       "1576306                   <NA>           <NA>       <NA>              <NA>   \n",
       "\n",
       "         year               date_H  FELONY  MISDEMEANOR  VIOLATION  \n",
       "0        2018  2018-01-01 00:00:00     7.0          8.0        2.0  \n",
       "1        2018  2018-01-01 00:00:00     7.0          8.0        2.0  \n",
       "2        2018  2018-01-01 00:00:00     1.0          8.0        1.0  \n",
       "3        2018  2018-01-01 00:00:00     6.0         15.0        5.0  \n",
       "4        2018  2018-01-01 00:00:00    11.0         13.0        4.0  \n",
       "...       ...                  ...     ...          ...        ...  \n",
       "1576302  <NA>                 <NA>     NaN          NaN        NaN  \n",
       "1576303  <NA>                 <NA>     NaN          NaN        NaN  \n",
       "1576304  <NA>                 <NA>     NaN          NaN        NaN  \n",
       "1576305  <NA>                 <NA>     NaN          NaN        NaN  \n",
       "1576306  <NA>                 <NA>     NaN          NaN        NaN  \n",
       "\n",
       "[1576307 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'strata_threshold_remove' from 'preprocessing.pre_survival' (c:\\Users\\Morri\\Documents\\Notebooks\\Capstone\\src\\preprocessing\\pre_survival.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mduration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazard_regression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PHReg, PHRegResults\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_survival\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strata_threshold_remove, process_categorical\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'strata_threshold_remove' from 'preprocessing.pre_survival' (c:\\Users\\Morri\\Documents\\Notebooks\\Capstone\\src\\preprocessing\\pre_survival.py)"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from lifelines import CoxPHFitter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sksurv.ensemble import (\n",
    "    ComponentwiseGradientBoostingSurvivalAnalysis,\n",
    "    GradientBoostingSurvivalAnalysis,\n",
    "    RandomSurvivalForest,\n",
    ")\n",
    "from statsmodels.duration.hazard_regression import PHReg, PHRegResults\n",
    "import multiprocessing as mp\n",
    "from preprocessing.pre_survival import strata_threshold_remove, process_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = int(mp.cpu_count() * 0.9)\n",
    "seed = 14\n",
    "rsf = RandomSurvivalForest(max_depth=3, min_samples_leaf=50, n_jobs=n_jobs, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = {\n",
    "    'hours_to_complete', 'descriptor', 'resolution_description',\n",
    "       'resolution_action_updated_date',\n",
    "       'incident_zip', 'city', 'bbl','status',\n",
    "       'closed_H','created_date',\n",
    "       'closed_date','sector',\n",
    "    #    'latitude', 'longitude',\n",
    "       'due_date','created','date_H',\n",
    "       'created', 'created_bo', 'created_ag', 'created_co',\n",
    "       'created_bo_ag', 'open', 'open_bo', 'open_ag', 'open_co',\n",
    "       'open_bo_ag','open_bo_co','precip_period_hrs', 'precip_accumulation_mm','direction_deg',\n",
    "    #    'created_bo_co','temperature_c','speed_mps','dew_temperature_c'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BRONX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours_to_complete\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrsf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhours_to_complete\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\sksurv\\ensemble\\forest.py:92\u001b[0m, in \u001b[0;36m_BaseSurvivalForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a forest of survival trees from the training set (X, y).\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m---> 92\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m event, time \u001b[38;5;241m=\u001b[39m check_array_survival(X, y)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\sklearn\\utils\\validation.py:838\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    837\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 838\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    840\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\arrays\\base.py:592\u001b[0m, in \u001b[0;36mExtensionArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimedeltaArray\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaArray\u001b[38;5;241m.\u001b[39m_from_sequence(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py:437\u001b[0m, in \u001b[0;36mArrowExtensionArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: NpDtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Correctly construct numpy arrays when passed to `np.asarray()`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py:1076\u001b[0m, in \u001b[0;36mArrowExtensionArray.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(data\u001b[38;5;241m.\u001b[39m_data, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1076\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1078\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Morri\\.conda\\envs\\capstone\\lib\\site-packages\\pyarrow\\table.pxi:531\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray.__array__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BRONX'"
     ]
    }
   ],
   "source": [
    "X = df[[c for c in df.columns if c not in remove_cols]]\n",
    "rsf.fit(X, df.hours_to_complete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
